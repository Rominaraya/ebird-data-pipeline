# üê¶ eBird Data Pipeline
[![Pipeline eBird](https://github.com/Rominaraya/ebird-data-pipeline/actions/workflows/pipeline_ebird.yml/badge.svg)](https://github.com/Rominaraya/ebird-data-pipeline/actions/workflows/pipeline_ebird.yml)
![Python](https://img.shields.io/badge/python-3.13.7-blue.svg)

Pipeline automatizado para la recolecci√≥n, transformaci√≥n y almacenamiento de datos de observaciones de aves de la localidad seleccionada, utilizando la API de eBird, Google Cloud Storage y BigQuery.  
La ejecuci√≥n est√° programada y gestionada mediante GitHub Actions.

## Uso de datos de eBird
Los datos utilizados en este proyecto provienen de la API p√∫blica de eBird.  
Fuente recomendada para citaci√≥n:  
eBird. 2025. eBird Basic Dataset. Cornell Lab of Ornithology, Ithaca, New York.

## Intenci√≥n del proyecto
El objetivo principal es crear un flujo de datos automatizado, reproducible y escalable que permita:

- Obtener registros actualizados por d√≠a de observaciones de aves en una regi√≥n espec√≠fica.
- Limpiar, validar y enriquecer los datos para an√°lisis  asegurar consistencia y trazabilidad.
- Almacenarlos en Google Cloud Storage y BigQuery para an√°lisis posteriores.

---

## Funcionalidad

1. **Ingesta (`ingest.py`)**  
   - Consulta la API de eBird para obtener observaciones del d√≠a anterior.  
   - Guarda los datos en formato JSON en la carpeta raw/ del bucket de GCS.

2. **Transformaci√≥n (`transform.py`)**  
   - Descarga el archivo m√°s reciente desde raw/. 
   - Aplica limpieza y validaci√≥n:  
     - Filtra observaciones v√°lidas (obsValid = True)  
     - Elimina columnas irrelevantes (locName, exoticCategory, etc.)  
     - Elimina duplicados (subId + speciesCode)
     - Normaliza fechas (obsDt) y extrae year, month, day
     - Convierte coordenadas a GEOGRAPHY (POINT(lng lat))
     - Filtra registros con howMany nulo o igual a 0
   - A√±ade la columna region_code extra√≠da del nombre del archivo.
   - Guarda el resultado como CSV en la carpeta processed/ del bucket.

3. **Carga (`load.py`)**  
   - Obtiene el √∫ltimo archivo procesado desde GCS. 
   - Carga los datos a BigQuery en la tabla ebird_data.ebird_avistamientos. 
   - Define el esquema manualmente, incluyendo tipos como TIMESTAMP, GEOGRAPHY, INTEGER, etc.
   - Usa WRITE_APPEND para conservar el hist√≥rico.

4. **Orquestaci√≥n (`run_pipeline.py`)**  
   - Ejecuta los pasos de ingesta, transformaci√≥n y carga en orden.  
   - Incluye logging y control de errores para trazabilidad.

5. **Automatizaci√≥n (`.github/workflows/pipeline_ebird.yml`)**  
   - Ejecuci√≥n programada todos los d√≠as a las 12:00 hora de Chile (15:00 UTC).  
   - Ejecuci√≥n manual disponible mediante `workflow_dispatch`.  
   - Configuraci√≥n de entorno y autenticaci√≥n a GCP mediante secretos.

---

## Variables de entorno

El pipeline requiere las siguientes variables (configuradas como GitHub Secrets o en un archivo `.env` local):

- `EBIRD_API_KEY` ‚Üí Clave de acceso a la API de eBird
- `GCS_BUCKET_NAME` ‚Üí Nombre del bucket en Google Cloud Storage.  
- `GCP_CREDENTIALS` ‚Üí Credenciales JSON de servicio para GCP.  

---
## Obtenci√≥n de la API Key de eBird

Para ejecutar este pipeline es necesario contar con una API Key personal de eBird.  
El proceso para obtenerla es el siguiente:

1. Crear una cuenta gratuita en [eBird](https://ebird.org) si a√∫n no la tienes.  
2. Iniciar sesi√≥n y dirigirse a la p√°gina de [solicitud de API Key](https://documenter.getpostman.com/view/664302/S1ENwy59).  
3. Generar la clave y copiarla.  
4. Configurarla como variable de entorno `EBIRD_API_KEY` en tu entorno local o en los Secrets de GitHub Actions.  

---

## Tecnolog√≠as utilizadas

- Python 3.13.7  
- eBird API  
- Google Cloud Storage  
- Google BigQuery  
- GitHub Actions (automatizaci√≥n)  
- Pandas (procesamiento de datos)

---
## Ejecuci√≥n local

```bash
# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows

# Instalar dependencias
pip install -r requirements.txt

# Ejecutar pipeline
python src/run_pipeline.py

```
---
## Visualizaci√≥n de datos de avistamientos de aves en Chile
Esta secci√≥n muestra ejemplos de an√°lisis  realizados sobre los datos cargados en BigQuery. Las visualizaciones fueron creadas en Looker Studio
a partir de consultas SQL ejecutadas directamente sobre la tabla ebird_data.ebird_avistamientos.

###  Consulta 1: Top 10 registros con mayor cantidad observada en Chile

```sql
SELECT
  comName AS nombre,
  howMany AS cantidad_registrada
FROM
  `ebirds-data-pipeline.ebird_data.ebird_avistamientos`
ORDER BY howMany DESC
LIMIT 10;
```
Esta consulta muestra los 10 registros individuales con mayor cantidad de aves observadas en todo el hist√≥rico disponible.

### Gr√°fico: Top 10 especies m√°s observadas
<img width="1085" height="707" alt="imagen" src="https://github.com/user-attachments/assets/ed27256b-7d70-4b08-9d03-7b887315f58c" />
Este gr√°fico muestra las especies con mayor cantidad total de avistamientos en el hist√≥rico disponible.


###  Consulta 1: Distribuci√≥n espacial de observaciones de aves en Chile

```sql
SELECT
  location,
  comName AS especie,
  howMany AS cantidad
FROM
  `ebirds-data-pipeline.ebird_data.ebird_avistamientos`;
```

### Mapa: Distribuci√≥n espacial de observaciones de aves en Chile
<img width="773" height="775" alt="imagen" src="https://github.com/user-attachments/assets/62045842-9bd1-4c62-98bc-ad1a3ab03e66" />

Este gr√°fico muestra los puntos geogr√°ficos donde se han registrado observaciones v√°lidas de aves en Chile continental.
Los datos fueron obtenidos desde la API de eBird y procesados en BigQuery.
